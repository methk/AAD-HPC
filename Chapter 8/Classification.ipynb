{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La proporzione tra job sintetici e originali nella classe anomala Ã¨ la stessa sia nel trainset che nel testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from tcn import TCN\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SPLIT = 0.8\n",
    "NORM_TOT = 2500\n",
    "ANOM_TOT = 500\n",
    "DIM = 18\n",
    "\n",
    "def normalize(x):\n",
    "    norm = StandardScaler().fit_transform(json.loads(x)).tolist()\n",
    "    return [val[:DIM] for val in norm]\n",
    "\n",
    "synth = pd.read_csv(os.path.join('data', 'synth_timeseries_anom_3.csv'), sep='|', header=0)\n",
    "synth['timeseries'] = synth['timeseries'].apply(normalize)\n",
    "\n",
    "synth_train_l1, synth_test_l1 = np.split(synth, [int(len(synth)*SPLIT)])\n",
    "del synth\n",
    "\n",
    "actual = pd.read_csv(os.path.join('data', 'actual_timeseries_anom_3.csv'), sep='|', header=0)\n",
    "actual['timeseries'] = actual['timeseries'].apply(normalize)\n",
    "\n",
    "actual = actual.sample(frac=1).reset_index(drop=True)\n",
    "actual = actual.groupby('label').head(NORM_TOT).reset_index(drop=True)\n",
    "\n",
    "actual_l0 = actual.loc[actual['label'] == 0] # NORM_TOT elements\n",
    "actual_l1 = actual.loc[actual['label'] == 1] # 86 elements\n",
    "del actual\n",
    "\n",
    "actual_train_l0, actual_test_l0 = np.split(actual_l0, [int(len(actual_l0)*SPLIT)])\n",
    "actual_train_l1, actual_test_l1 = np.split(actual_l1, [int(len(actual_l1)*SPLIT)])\n",
    "del actual_l0\n",
    "del actual_l1\n",
    "\n",
    "train_df = actual_train_l0.append(actual_train_l1.append(synth_train_l1, ignore_index=True), ignore_index=True)\n",
    "test_df = actual_test_l0.append(actual_test_l1.append(synth_test_l1, ignore_index=True), ignore_index=True)\n",
    "del actual_train_l0\n",
    "del actual_train_l1\n",
    "del synth_train_l1\n",
    "del actual_test_l0\n",
    "del actual_test_l1\n",
    "del synth_test_l1\n",
    "\n",
    "# build train dataset\n",
    "\n",
    "train_X = train_df['timeseries'].tolist()\n",
    "train_Y = train_df['label'].tolist()\n",
    "del train_df\n",
    "\n",
    "print(f'Train dataset: {Counter(train_Y)}')\n",
    "tmp = list(zip(train_X, train_Y))\n",
    "random.shuffle(tmp)\n",
    "train_X, train_Y = zip(*tmp)\n",
    "\n",
    "# build test dataset\n",
    "\n",
    "test_X = test_df['timeseries'].tolist()\n",
    "test_Y = test_df['label'].tolist()\n",
    "del test_df\n",
    "\n",
    "print(f'Test dataset: {Counter(test_Y)}')\n",
    "tmp = list(zip(test_X, test_Y))\n",
    "random.shuffle(tmp)\n",
    "test_X, test_Y = zip(*tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_gen():\n",
    "    while True:\n",
    "        for i in range(len(train_X)):\n",
    "            yield np.expand_dims(train_X[i], axis=0), np.expand_dims(train_Y[i], axis=(0, 1))\n",
    "\n",
    "def test_data_gen():\n",
    "    while True:\n",
    "        for i in range(len(test_X)):\n",
    "            yield np.expand_dims(test_X[i], axis=0), np.expand_dims(test_Y[i], axis=(0, 1))\n",
    "\n",
    "TRAINSET_SIZE = len(train_X)\n",
    "TESTSET_SIZE = len(test_X)\n",
    "EPOCHS = 40\n",
    "\n",
    "i = Input(batch_shape=(1, None, DIM))\n",
    "\n",
    "o = TCN(nb_filters=8, kernel_size=4, nb_stacks=1, dilations=(1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024), use_layer_norm=True, dropout_rate=0.3)(i)\n",
    "o = Dense(1, activation='sigmoid')(o)\n",
    "\n",
    "m = Model(inputs=[i], outputs=[o])\n",
    "m.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', Recall(), Precision(), AUC()])\n",
    "\n",
    "hist = m.fit(train_data_gen(), epochs=EPOCHS, steps_per_epoch=TRAINSET_SIZE, max_queue_size=1, validation_data=test_data_gen(), validation_steps=TESTSET_SIZE)\n",
    "    \n",
    "acc = hist.history['accuracy']\n",
    "loss = hist.history['loss']\n",
    "auc = hist.history['auc']\n",
    "precision = hist.history['precision']\n",
    "recall = hist.history['recall']\n",
    "fscore = [2*((precision[i]*recall[i])/(precision[i]+recall[i])) for i in range(len(precision))]\n",
    "\n",
    "val_acc = hist.history['val_accuracy']\n",
    "val_loss = hist.history['val_loss']\n",
    "val_auc = hist.history['val_auc']\n",
    "val_precision = hist.history['val_precision']\n",
    "val_recall = hist.history['val_recall']\n",
    "val_fscore = [2*((val_precision[i]*val_recall[i])/(val_precision[i]+val_recall[i])) for i in range(len(val_precision))]\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.plot(acc, color='#885A89')\n",
    "plt.plot(val_acc, color='#613F61')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(loss, color='#8AA8A1')\n",
    "plt.plot(val_loss, color='#5B7B74')\n",
    "plt.show()\n",
    "\n",
    "plt.title('AUC')\n",
    "plt.plot(auc, color='green')\n",
    "plt.plot(val_auc, color='green')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Precision')\n",
    "plt.plot(precision, color='#CBCBD4')\n",
    "plt.plot(val_precision, color='#87879B')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Recall')\n",
    "plt.plot(recall, color='#D1B490')\n",
    "plt.plot(val_recall, color='#AE8049')\n",
    "plt.show()\n",
    "\n",
    "plt.title('FScore')\n",
    "plt.plot(fscore, color='#EE7B30')\n",
    "plt.plot(val_fscore, color='#B9530F')\n",
    "plt.show()\n",
    "\n",
    "f = open('history.txt', 'a+')\n",
    "f.write(f'{acc}|{loss}|{auc}|{precision}|{recall}|{fscore}|{val_acc}|{val_loss}|{val_auc}|{val_precision}|{val_recall}|{val_fscore}\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9861608982086182\n",
      "training loss: 0.0402168445289135\n",
      "training AUC-ROC: 0.996762490272522\n",
      "training precision: 0.9588644623756408\n",
      "training recall: 0.9578947424888611\n",
      "training F1-score: 0.9583717557864718\n",
      "testing accuracy: 0.9783693671226501\n",
      "testing loss: 0.08703010529279709\n",
      "testing AUC-ROC: 0.9890316486358642\n",
      "testing precision: 0.9282669425010681\n",
      "testing recall: 0.9445544600486755\n",
      "testing F1-score: 0.9359512054677859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metrics = ['acc', 'loss', 'auc', 'precision', 'recall', 'fscore', 'val_acc', 'val_loss', 'val_auc', 'val_precision', 'val_recall', 'val_fscore']\n",
    "labels = ['training accuracy', 'training loss', 'training AUC-ROC', 'training precision', 'training recall', 'training F1-score', 'testing accuracy', 'testing loss', 'testing AUC-ROC', 'testing precision', 'testing recall', 'testing F1-score']\n",
    "colors = ['#C33149', '#156064', '#F18F01', '#7006C7', '#C706B4', '#26A96C', '#C33149', '#156064', '#F18F01', '#7006C7', '#C706B4', '#26A96C']\n",
    "\n",
    "for j, metric in enumerate(metrics):\n",
    "    hist = open('history_3000_40.txt', 'r')\n",
    "    pool = []\n",
    "    for i, line in enumerate(hist):\n",
    "        splt = line.split('|')\n",
    "        acc = json.loads(splt[j])\n",
    "        pool.append(np.array(acc))\n",
    "        plt.ylim([0, 1])\n",
    "        plt.plot(acc, color=colors[j], alpha=0.4+((i+1)/6)*0.3)\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel(labels[j])\n",
    "    m = [np.mean(k) for k in zip(*pool)]\n",
    "    print(f'{labels[j]}: {m[-1]}')\n",
    "    plt.plot(m, color=colors[j])\n",
    "#     plt.show()\n",
    "    plt.savefig('plots/3000/' + metrics[j] + '.png')\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
